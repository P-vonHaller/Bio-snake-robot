{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-2-8310dc12e6dc>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-8310dc12e6dc>\"\u001b[1;36m, line \u001b[1;32m22\u001b[0m\n\u001b[1;33m    DATA_DIRECTORY = 'C:\\Users\\Robert Feussner\\Desktop\\VOCdevkit\\VOC2012'\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from deeplab.model import Res_Deeplab\n",
    "from deeplab.datasets import VOCDataSet\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "IMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n",
    "\n",
    "DATA_DIRECTORY = 'C:\\Users\\Robert Feussner\\Desktop\\VOCdevkit\\VOC2012'\n",
    "DATA_LIST_PATH = './dataset/list/val.txt'\n",
    "IGNORE_LABEL = 255\n",
    "NUM_CLASSES = 21\n",
    "NUM_STEPS = 1449 # Number of images in the validation set.\n",
    "RESTORE_FROM = './deeplab_resnet.ckpt'\n",
    "\n",
    "def get_arguments():\n",
    "    \"\"\"Parse all the arguments provided from the CLI.\n",
    "    \n",
    "    Returns:\n",
    "      A list of parsed arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"DeepLabLFOV Network\")\n",
    "    parser.add_argument(\"--data-dir\", type=str, default=DATA_DIRECTORY,\n",
    "                        help=\"Path to the directory containing the PASCAL VOC dataset.\")\n",
    "    parser.add_argument(\"--data-list\", type=str, default=DATA_LIST_PATH,\n",
    "                        help=\"Path to the file listing the images in the dataset.\")\n",
    "    parser.add_argument(\"--ignore-label\", type=int, default=IGNORE_LABEL,\n",
    "                        help=\"The index of the label to ignore during the training.\")\n",
    "    parser.add_argument(\"--num-classes\", type=int, default=NUM_CLASSES,\n",
    "                        help=\"Number of classes to predict (including background).\")\n",
    "    parser.add_argument(\"--restore-from\", type=str, default=RESTORE_FROM,\n",
    "                        help=\"Where restore model parameters from.\")\n",
    "    parser.add_argument(\"--gpu\", type=int, default=0,\n",
    "                        help=\"choose gpu device.\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def get_iou(data_list, class_num, save_path=None):\n",
    "    from multiprocessing import Pool \n",
    "    from deeplab.metric import ConfusionMatrix\n",
    "\n",
    "    ConfM = ConfusionMatrix(class_num)\n",
    "    f = ConfM.generateM\n",
    "    pool = Pool() \n",
    "    m_list = pool.map(f, data_list)\n",
    "    pool.close() \n",
    "    pool.join() \n",
    "    \n",
    "    for m in m_list:\n",
    "        ConfM.addM(m)\n",
    "\n",
    "    aveJ, j_list, M = ConfM.jaccard()\n",
    "    print('meanIOU: ' + str(aveJ) + '\\n')\n",
    "    if save_path:\n",
    "        with open(save_path, 'w') as f:\n",
    "            f.write('meanIOU: ' + str(aveJ) + '\\n')\n",
    "            f.write(str(j_list)+'\\n')\n",
    "            f.write(str(M)+'\\n')\n",
    "\n",
    "def show_all(gt, pred):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import colors\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "    fig1 = plt.figure()\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    classes = np.array(('background',  # always index 0\n",
    "               'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                         'cow', 'diningtable', 'dog', 'horse',\n",
    "                         'motorbike', 'person', 'pottedplant',\n",
    "                         'sheep', 'sofa', 'train', 'tvmonitor'))\n",
    "    colormap = [(0,0,0),(0.5,0,0),(0,0.5,0),(0.5,0.5,0),(0,0,0.5),(0.5,0,0.5),(0,0.5,0.5), \n",
    "                    (0.5,0.5,0.5),(0.25,0,0),(0.75,0,0),(0.25,0.5,0),(0.75,0.5,0),(0.25,0,0.5), \n",
    "                    (0.75,0,0.5),(0.25,0.5,0.5),(0.75,0.5,0.5),(0,0.25,0),(0.5,0.25,0),(0,0.75,0), \n",
    "                    (0.5,0.75,0),(0,0.25,0.5)]\n",
    "    cmap = colors.ListedColormap(colormap)\n",
    "    bounds=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    ax1.set_title('gt')\n",
    "    ax1.imshow(gt, cmap=cmap, norm=norm)\n",
    "\n",
    "    ax2.set_title('pred')\n",
    "    ax2.imshow(pred, cmap=cmap, norm=norm)\n",
    "\n",
    "    fig1.savefig('1.png')\n",
    "\n",
    "def main():\n",
    "    \"\"\"Create the model and start the evaluation process.\"\"\"\n",
    "    args = get_arguments()\n",
    "\n",
    "    gpu0 = args.gpu\n",
    "\n",
    "    model = Res_Deeplab(num_classes=args.num_classes)\n",
    "    \n",
    "    saved_state_dict = torch.load(args.restore_from)\n",
    "    model.load_state_dict(saved_state_dict)\n",
    "\n",
    "    model.eval()\n",
    "    model.cuda(gpu0)\n",
    "\n",
    "    testloader = data.DataLoader(VOCDataSet(args.data_dir, args.data_list, crop_size=(505, 505), mean=IMG_MEAN, scale=False, mirror=False), \n",
    "                                    batch_size=1, shuffle=False, pin_memory=True)\n",
    "\n",
    "    interp = nn.Upsample(size=(505, 505), mode='bilinear', align_corners=True)\n",
    "    data_list = []\n",
    "\n",
    "    for index, batch in enumerate(testloader):\n",
    "        if index > 2:\n",
    "            break\n",
    "        if index % 100 == 0:\n",
    "            print('%d processd'%(index))\n",
    "        image, label, size, name = batch\n",
    "        size = size[0].numpy()\n",
    "        output = model(Variable(image, volatile=True).cuda(gpu0))\n",
    "        output = interp(output).cpu().data[0].numpy()\n",
    "\n",
    "        output = output[:,:size[0],:size[1]]\n",
    "        gt = np.asarray(label[0].numpy()[:size[0],:size[1]], dtype=np.int)\n",
    "        \n",
    "        output = output.transpose(1,2,0)\n",
    "        output = np.asarray(np.argmax(output, axis=2), dtype=np.int)\n",
    "\n",
    "        show_all(gt, output)\n",
    "        data_list.append([gt.flatten(), output.flatten()])\n",
    "\n",
    "    #get_iou(data_list, args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
